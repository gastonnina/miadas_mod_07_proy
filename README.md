<!-- omit in toc -->
# ðŸ—ï¸ Proyecto: ETL y ValidaciÃ³n de Calidad de Datos â€“ TrÃ¡mites Municipales de La Paz

> âš ï¸ **Nota AcadÃ©mica:**  
> Este proyecto es de carÃ¡cter **experimental** y forma parte del **MÃ³dulo 7 â€“ AdquisiciÃ³n y ComprensiÃ³n de Datos** de la **MaestrÃ­a en Inteligencia Artificial y Data Science para la TransformaciÃ³n de Negocios (MIADAS 2)**,  
> orientado al aprendizaje prÃ¡ctico de procesos **ETL, calidad de datos y orquestaciÃ³n con Airflow**.


<!-- omit in toc -->
## Tabala de contenidos
- [ðŸ‘¥ Integrantes (Grupo 2)](#-integrantes-grupo-2)
- [ðŸ“ Estructura del Repositorio](#-estructura-del-repositorio)
- [ðŸŽ¯ Objetivo del Proyecto](#-objetivo-del-proyecto)
- [ðŸ§­ Diagrama del Flujo ETL](#-diagrama-del-flujo-etl)
- [ðŸ“¦ Entregables](#-entregables)
- [ðŸ” DescripciÃ³n de los Notebooks](#-descripciÃ³n-de-los-notebooks)
- [âš™ï¸ Pipeline Airflow](#ï¸-pipeline-airflow)
  - [Estructura del flujo:](#estructura-del-flujo)
- [ðŸ“Š Reporte de Calidad](#-reporte-de-calidad)
- [ðŸ§© Herramientas y LibrerÃ­as](#-herramientas-y-librerÃ­as)
- [ðŸ—ï¸ Arquitectura Propuesta](#ï¸-arquitectura-propuesta)
- [ðŸ“˜ Referencias](#-referencias)


## ðŸ‘¥ Integrantes (Grupo 2)
- **Ericka Cori**  
- **Paolo Ramos**  
- **Gaston Nina**

---

## ðŸ“ Estructura del Repositorio

```
.
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ df_modelo_limpio_1.csv
â”‚   â”œâ”€â”€ tramites_html_identificador.csv
â”‚   â””â”€â”€ tramites_lapaz_api_identificador.csv
â”‚
â”œâ”€â”€ diccionario/
â”‚   â”œâ”€â”€ Diccionario de Datos.pdf
â”‚   â””â”€â”€ Diccionario de Datos.xlsx
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ mod_07_Scrapy.ipynb
â”‚   â”œâ”€â”€ mod_07_transformacion.ipynb
â”‚   â””â”€â”€ mod_07_QUALITY.ipynb
â”‚
â”œâ”€â”€ pipeline_airflow/
â”‚   â””â”€â”€ dags/
â”‚   â”œâ”€â”€ tramites_lapaz_extract.py
â”‚   â”œâ”€â”€ tramites_lapaz_pipeline.py
â”‚   â”œâ”€â”€ tramites_lapaz_report.py
â”‚   â””â”€â”€ tramites_lapaz_transform.py
â”‚
â”œâ”€â”€ reporte_de_calidad/
â”‚   â””â”€â”€ quality_report.html
â”‚
â”œâ”€â”€ INFORME FINAL.pdf
â”œâ”€â”€ Presentacion.pdf
â””â”€â”€ README.md
```

---

## ðŸŽ¯ Objetivo del Proyecto

El objetivo es desarrollar un **pipeline ETL completo** para los datos de trÃ¡mites municipales del Gobierno AutÃ³nomo Municipal de La Paz, aplicando tÃ©cnicas de:
- **ExtracciÃ³n** mediante scraping y APIs.
- **TransformaciÃ³n y limpieza** de datos.
- **ValidaciÃ³n de calidad** con herramientas como *Great Expectations*.
- **OrquestaciÃ³n** mediante *Apache Airflow*.


## ðŸ§­ Diagrama del Flujo ETL

El siguiente diagrama resume las etapas principales del proceso **ETL (Extract, Transform, Load)** aplicadas sobre los datos municipales:

![Flujo ETL](assets/etl_pipeline.png)

**DescripciÃ³n general:**
1. **ExtracciÃ³n:** datos obtenidos desde la API del GeoServer municipal y pÃ¡ginas HTML mediante *BeautifulSoup* y *Scrapy*.  
2. **TransformaciÃ³n:** limpieza, uniÃ³n, eliminaciÃ³n de duplicados y tratamiento de nulos.  
3. **Carga:** exportaciÃ³n de los resultados a archivos CSV para anÃ¡lisis y validaciÃ³n de calidad.  
4. **TecnologÃ­as:** desarrollo en *Python* con librerÃ­as como *NumPy* y *Pandas*.


## ðŸ“¦ Entregables

| Entregable | DescripciÃ³n |
|-------------|--------------|
| **CÃ³digo fuente** | Repositorio estructurado con [notebooks](notebooks/) y [scripts base para migraciÃ³n a Airflow](pipeline_airflow/dags/). |
| **Dataset limpio generado** | Archivo [`df_modelo_limpio_1.csv`](data/df_modelo_limpio_1.csv) con los registros depurados y transformados. |
| **Diccionario de datos** | DescripciÃ³n de las variables, tipos y significados en [`Diccionario de Datos.xlsx`](diccionario/Diccionario%20de%20Datos.xlsx). |
| **Data Quality Report** | Reporte automÃ¡tico de calidad generado con *Great Expectations* y *pandas-profiling*: [`quality_report.html`](reporte_de_calidad/quality_report.html). |
| **Pipeline orquestado** | Flujo ETL implementado en [`pipeline_airflow/dags/`](pipeline_airflow/dags/). |
| **Arquitectura propuesta** | Documento principal del proyecto: [`INFORME FINAL.pdf`](INFORME%20FINAL.pdf). |


---

## ðŸ” DescripciÃ³n de los Notebooks

| Notebook | DescripciÃ³n |
|-----------|-------------|
| `mod_07_Scrapy.ipynb` | ExtracciÃ³n de datos desde HTML y API municipal. |
| `mod_07_transformacion.ipynb` | Limpieza, normalizaciÃ³n y uniÃ³n de datasets. |
| `mod_07_QUALITY.ipynb` | ValidaciÃ³n de calidad con *pandas-profiling* y *Great Expectations*. |

---

## âš™ï¸ Pipeline Airflow

La carpeta `pipeline_airflow/dags/` contiene los **DAGs** que replican y automatizan el flujo de los notebooks mediante **Apache Airflow**.

### Estructura del flujo:
1. **ExtracciÃ³n:** obtenciÃ³n de datos desde fuentes HTML y API.
2. **TransformaciÃ³n:** limpieza, estandarizaciÃ³n y uniÃ³n de datasets.
3. **ValidaciÃ³n de calidad:** expectativas automÃ¡ticas con *Great Expectations*.
4. **Reporte:** generaciÃ³n de informes HTML y dataset final.

> **ðŸ’¡ Importante:**
> Para que Airflow ejecute correctamente los flujos, copia la carpeta `pipeline_airflow/dags/` dentro del directorio `dags` de tu instalaciÃ³n de Airflow, por ejemplo:
> ```
> ~/airflow/dags/
> ```


---

## ðŸ“Š Reporte de Calidad

Se generÃ³ automÃ¡ticamente usando **pandas-profiling / ydata-profiling** y **Great Expectations**, validando:
- Valores nulos, duplicados y rangos esperados.
- Consistencia de latitud/longitud.
- RelaciÃ³n entre superficie legal y construida.

El reporte estÃ¡ disponible en:
```
reporte_de_calidad/quality_report.html
```

---

## ðŸ§© Herramientas y LibrerÃ­as

- **Python 3.12+**
- **Pandas**, **NumPy**
- **BeautifulSoup4**, **Requests**
- **Great Expectations**
- **Apache Airflow**

---

## ðŸ—ï¸ Arquitectura Propuesta

El diseÃ±o sigue la arquitectura tÃ­pica de un pipeline ETL:

```
[ExtracciÃ³n] --> [TransformaciÃ³n y Limpieza] --> [ValidaciÃ³n de Calidad] --> [Carga y Reporte]
       |                    |                          |                         |
   Scrapy/API           Pandas/Polars          Great Expectations       HTML/CSV Output
```

El flujo serÃ¡ orquestado por **Apache Airflow**, asegurando reproducibilidad, trazabilidad y monitoreo de cada etapa.

---

## ðŸ“˜ Referencias

- [Great Expectations Documentation](https://docs.greatexpectations.io/)
- [Pandas Profiling / YData Profiling](https://ydata-profiling.ydata.ai/docs/master/)
- [Apache Airflow](https://airflow.apache.org/)