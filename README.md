<!-- omit in toc -->
# üèóÔ∏è Proyecto: ETL y Validaci√≥n de Calidad de Datos ‚Äì Tr√°mites Municipales de La Paz

> ‚ö†Ô∏è **Nota Acad√©mica:**  
> Este proyecto es de car√°cter **experimental** y forma parte del **M√≥dulo 7 ‚Äì Adquisici√≥n y Comprensi√≥n de Datos** de la **Maestr√≠a en Inteligencia Artificial y Data Science para la Transformaci√≥n de Negocios (MIADAS 2)**,  
> orientado al aprendizaje pr√°ctico de procesos **ETL, calidad de datos y orquestaci√≥n con Airflow**.


<!-- omit in toc -->
## Tabala de contenidos
- [üë• Integrantes (Grupo 2)](#-integrantes-grupo-2)
- [üìÅ Estructura del Repositorio](#-estructura-del-repositorio)
- [üéØ Objetivo del Proyecto](#-objetivo-del-proyecto)
- [üß≠ Diagrama del Flujo ETL](#-diagrama-del-flujo-etl)
- [üì¶ Entregables](#-entregables)
- [üîç Descripci√≥n de los Notebooks](#-descripci√≥n-de-los-notebooks)
  - [üöÄ Ejecuci√≥n de los notebooks](#-ejecuci√≥n-de-los-notebooks)
- [‚öôÔ∏è Pipeline Airflow](#Ô∏è-pipeline-airflow)
  - [Estructura del flujo:](#estructura-del-flujo)
- [üìä Reporte de Calidad](#-reporte-de-calidad)
- [üß© Herramientas y Librer√≠as](#-herramientas-y-librer√≠as)
- [üèóÔ∏è Arquitectura Propuesta](#Ô∏è-arquitectura-propuesta)


## üë• Integrantes (Grupo 2)
- **Ericka Cori**  
- **Paolo Ramos**  
- **Gaston Nina**

---

## üìÅ Estructura del Repositorio

```
.
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ df_modelo_limpio_1.csv
‚îÇ   ‚îú‚îÄ‚îÄ tramites_html_identificador.csv
‚îÇ   ‚îî‚îÄ‚îÄ tramites_lapaz_api_identificador.csv
‚îÇ
‚îú‚îÄ‚îÄ diccionario/
‚îÇ   ‚îú‚îÄ‚îÄ Diccionario de Datos.pdf
‚îÇ   ‚îî‚îÄ‚îÄ Diccionario de Datos.xlsx
‚îÇ
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ mod_07_Scrapy.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ mod_07_transformacion.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ mod_07_QUALITY.ipynb
‚îÇ
‚îú‚îÄ‚îÄ pipeline_airflow/
‚îÇ   ‚îî‚îÄ‚îÄ dags/
‚îÇ   ‚îú‚îÄ‚îÄ tramites_lapaz_extract.py
‚îÇ   ‚îú‚îÄ‚îÄ tramites_lapaz_pipeline.py
‚îÇ   ‚îú‚îÄ‚îÄ tramites_lapaz_report.py
‚îÇ   ‚îî‚îÄ‚îÄ tramites_lapaz_transform.py
‚îÇ
‚îú‚îÄ‚îÄ reporte_de_calidad/
‚îÇ   ‚îî‚îÄ‚îÄ quality_report.html
‚îÇ
‚îú‚îÄ‚îÄ INFORME FINAL.pdf
‚îú‚îÄ‚îÄ Presentacion.pdf
‚îî‚îÄ‚îÄ README.md
```

---

## üéØ Objetivo del Proyecto

El objetivo es desarrollar un **pipeline ETL completo** para los datos de tr√°mites municipales del Gobierno Aut√≥nomo Municipal de La Paz, aplicando t√©cnicas de:
- **Extracci√≥n** mediante scraping y APIs.
- **Transformaci√≥n y limpieza** de datos.
- **Validaci√≥n de calidad** con herramientas como *Great Expectations*.
- **Orquestaci√≥n** mediante *Apache Airflow*.


## üß≠ Diagrama del Flujo ETL

El siguiente diagrama resume las etapas principales del proceso **ETL (Extract, Transform, Load)** aplicadas sobre los datos municipales:

![Flujo ETL](assets/etl_pipeline.png)

**Descripci√≥n general:**
1. **Extracci√≥n:** datos obtenidos desde la API del GeoServer municipal y p√°ginas HTML mediante *BeautifulSoup* y *Scrapy*.  
2. **Transformaci√≥n:** limpieza, uni√≥n, eliminaci√≥n de duplicados y tratamiento de nulos.  
3. **Carga:** exportaci√≥n de los resultados a archivos CSV para an√°lisis y validaci√≥n de calidad.  
4. **Tecnolog√≠as:** desarrollo en *Python* con librer√≠as como *NumPy* y *Pandas*.


## üì¶ Entregables

| Entregable | Descripci√≥n |
|-------------|--------------|
| **C√≥digo fuente** | Repositorio estructurado con [notebooks](notebooks/) y [scripts base para migraci√≥n a Airflow](pipeline_airflow/dags/). |
| **Dataset limpio generado** | Archivo [`df_modelo_limpio_1.csv`](data/df_modelo_limpio_1.csv) con los registros depurados y transformados. |
| **Diccionario de datos** | Descripci√≥n de las variables, tipos y significados en [`Diccionario de Datos.xlsx`](diccionario/Diccionario%20de%20Datos.xlsx). |
| **Data Quality Report** | Reporte autom√°tico de calidad generado con *Great Expectations* y *pandas-profiling*: [`quality_report.html`](reporte_de_calidad/quality_report.html). |
| **Pipeline orquestado** | Flujo ETL implementado en [`pipeline_airflow/dags/`](pipeline_airflow/dags/). |
| **Arquitectura propuesta** | Documento principal del proyecto: [`INFORME FINAL.pdf`](INFORME%20FINAL.pdf). |


---

## üîç Descripci√≥n de los Notebooks

| Notebook | Descripci√≥n |
|-----------|-------------|
| `mod_07_Scrapy.ipynb` | Extracci√≥n de datos desde HTML y API municipal. |
| `mod_07_transformacion.ipynb` | Limpieza, normalizaci√≥n y uni√≥n de datasets. |
| `mod_07_QUALITY.ipynb` | Validaci√≥n de calidad con *pandas-profiling* y *Great Expectations*. |

### üöÄ Ejecuci√≥n de los notebooks

Los notebooks pueden ejecutarse de forma sencilla en:

- **Google Colab** ‚Üí subiendo directamente cada archivo `.ipynb`.  
- **Jupyter Notebook** o **VS Code** (si cuentas con Python 3.12+ instalado).

> üí° Se recomienda usar **Google Colab** para facilitar la ejecuci√≥n sin necesidad de instalar dependencias locales.

---

## ‚öôÔ∏è Pipeline Airflow

La carpeta `pipeline_airflow/dags/` contiene los **DAGs** que replican y automatizan el flujo de los notebooks mediante **Apache Airflow**.

### Estructura del flujo:
1. **Extracci√≥n:** obtenci√≥n de datos desde fuentes HTML y API.
2. **Transformaci√≥n:** limpieza, estandarizaci√≥n y uni√≥n de datasets.
3. **Validaci√≥n de calidad:** expectativas autom√°ticas con *Great Expectations*.
4. **Reporte:** generaci√≥n de informes HTML y dataset final.

> **üí° Importante:**
> Para que Airflow ejecute correctamente los flujos, copia la carpeta `pipeline_airflow/dags/` dentro del directorio `dags` de tu instalaci√≥n de Airflow, por ejemplo:
> ```
> ~/airflow/dags/
> ```


---

## üìä Reporte de Calidad

Se gener√≥ autom√°ticamente usando **pandas-profiling / ydata-profiling** y **Great Expectations**, validando:
- Valores nulos, duplicados y rangos esperados.
- Consistencia de latitud/longitud.
- Relaci√≥n entre superficie legal y construida.

El reporte est√° disponible en:
```
reporte_de_calidad/quality_report.html
```

---

## üß© Herramientas y Librer√≠as

- **Python 3.12+**
- **Pandas**, **NumPy**
- **BeautifulSoup4**, **Requests**
- **Great Expectations**
- **Apache Airflow**

---

## üèóÔ∏è Arquitectura Propuesta

El dise√±o sigue la arquitectura t√≠pica de un pipeline ETL:

```
[Extracci√≥n] --> [Transformaci√≥n y Limpieza] --> [Validaci√≥n de Calidad] --> [Carga y Reporte]
       |                    |                          |                         |
   Scrapy/API           Pandas/Polars          Great Expectations       HTML/CSV Output
```

El flujo ser√° orquestado por **Apache Airflow**, asegurando reproducibilidad, trazabilidad y monitoreo de cada etapa.

---