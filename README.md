<!-- omit in toc -->
# ğŸ—ï¸ Proyecto: ETL y ValidaciÃ³n de Calidad de Datos â€“ TrÃ¡mites Municipales de La Paz

<!-- omit in toc -->
## Tabala de contenidos
- [ğŸ‘¥ Integrantes (Grupo 2)](#-integrantes-grupo-2)
- [ğŸ“ Estructura del Repositorio](#-estructura-del-repositorio)
- [ğŸ¯ Objetivo del Proyecto](#-objetivo-del-proyecto)
- [ğŸ“¦ Entregables](#-entregables)
- [ğŸ” DescripciÃ³n de los Notebooks](#-descripciÃ³n-de-los-notebooks)
- [âš™ï¸ Pipeline Airflow](#ï¸-pipeline-airflow)
- [ğŸ“Š Reporte de Calidad](#-reporte-de-calidad)
- [ğŸ§© Herramientas y LibrerÃ­as](#-herramientas-y-librerÃ­as)
- [ğŸ—ï¸ Arquitectura Propuesta](#ï¸-arquitectura-propuesta)
- [ğŸ“˜ Referencias](#-referencias)


## ğŸ‘¥ Integrantes (Grupo 2)
- **Ericka Cori**  
- **Paolo Ramos**  
- **Gaston Nina**

---

## ğŸ“ Estructura del Repositorio

```
.
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ df_modelo_limpio_1.csv
â”‚   â”œâ”€â”€ tramites_html_identificador.csv
â”‚   â””â”€â”€ tramites_lapaz_api_identificador.csv
â”‚
â”œâ”€â”€ diccionario/
â”‚   â”œâ”€â”€ Diccionario de Datos.pdf
â”‚   â””â”€â”€ Diccionario de Datos.xlsx
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ mod_07_Scrapy.ipynb
â”‚   â”œâ”€â”€ mod_07_transformacion.ipynb
â”‚   â””â”€â”€ mod_07_QUALITY.ipynb
â”‚
â”œâ”€â”€ pipeline_airflow/
â”‚   â””â”€â”€ .keep
â”‚
â”œâ”€â”€ reporte_de_calidad/
â”‚   â””â”€â”€ quality_report.html
â”‚
â”œâ”€â”€ INFORME FINAL.pdf
â””â”€â”€ README.md
```

---

## ğŸ¯ Objetivo del Proyecto

El objetivo es desarrollar un **pipeline ETL completo** para los datos de trÃ¡mites municipales del Gobierno AutÃ³nomo Municipal de La Paz, aplicando tÃ©cnicas de:
- **ExtracciÃ³n** mediante scraping y APIs.
- **TransformaciÃ³n y limpieza** de datos.
- **ValidaciÃ³n de calidad** con herramientas como *Great Expectations*.
- **OrquestaciÃ³n** mediante *Apache Airflow*.

---

## ğŸ“¦ Entregables

| Entregable | DescripciÃ³n |
|-------------|--------------|
| **CÃ³digo fuente** | Repositorio estructurado con notebooks y scripts base para migraciÃ³n a Airflow. |
| **Dataset limpio generado** | Archivo `df_modelo_limpio_1.csv` con los registros depurados y transformados. |
| **Diccionario de datos** | DescripciÃ³n de las variables, tipos y significados (`diccionario/Diccionario de Datos.xlsx`). |
| **Data Quality Report** | Reporte automÃ¡tico de calidad (`reporte_de_calidad/quality_report.html`). |
| **Pipeline orquestado** | Flujo ETL en desarrollo bajo la carpeta `pipeline_airflow/`, donde se migrarÃ¡n los procesos de los notebooks. |
| **Arquitectura propuesta** | Diagrama explicativo incluido en el informe (`INFORME FINAL.pdf`). |

---

## ğŸ” DescripciÃ³n de los Notebooks

| Notebook | DescripciÃ³n |
|-----------|-------------|
| `mod_07_Scrapy.ipynb` | ExtracciÃ³n de datos desde HTML y API municipal. |
| `mod_07_transformacion.ipynb` | Limpieza, normalizaciÃ³n y uniÃ³n de datasets. |
| `mod_07_QUALITY.ipynb` | ValidaciÃ³n de calidad con *pandas-profiling* y *Great Expectations*. |

---

## âš™ï¸ Pipeline Airflow

La carpeta `pipeline_airflow/` contendrÃ¡ el **DAG principal** encargado de ejecutar el flujo de datos equivalente a los notebooks.  
El pipeline incluirÃ¡ las siguientes tareas:

1. **ExtracciÃ³n:** obtenciÃ³n de datos desde fuentes locales y API.
2. **TransformaciÃ³n:** limpieza y normalizaciÃ³n.
3. **ValidaciÃ³n de calidad:** expectativas automÃ¡ticas sobre el dataset final.
4. **Carga y exportaciÃ³n:** almacenamiento de resultados y reporte.

> **Nota:** actualmente contiene un archivo `.keep` como marcador. El flujo completo se implementarÃ¡ en la prÃ³xima iteraciÃ³n migrando el contenido de los notebooks.

---

## ğŸ“Š Reporte de Calidad

Se generÃ³ automÃ¡ticamente usando **pandas-profiling / ydata-profiling** y **Great Expectations**, validando:
- Valores nulos, duplicados y rangos esperados.
- Consistencia de latitud/longitud.
- RelaciÃ³n entre superficie legal y construida.

El reporte estÃ¡ disponible en:
```
reporte_de_calidad/quality_report.html
```

---

## ğŸ§© Herramientas y LibrerÃ­as

- **Python 3.12+**
- **Pandas**, **NumPy**
- **BeautifulSoup4**, **Requests**
- **Great Expectations**
- **Apache Airflow**

---

## ğŸ—ï¸ Arquitectura Propuesta

El diseÃ±o sigue la arquitectura tÃ­pica de un pipeline ETL:

```
[ExtracciÃ³n] --> [TransformaciÃ³n y Limpieza] --> [ValidaciÃ³n de Calidad] --> [Carga y Reporte]
       |                    |                          |                         |
   Scrapy/API           Pandas/Polars          Great Expectations       HTML/CSV Output
```

El flujo serÃ¡ orquestado por **Apache Airflow**, asegurando reproducibilidad, trazabilidad y monitoreo de cada etapa.

---

## ğŸ“˜ Referencias

- [Great Expectations Documentation](https://docs.greatexpectations.io/)
- [Pandas Profiling / YData Profiling](https://ydata-profiling.ydata.ai/docs/master/)
- [Apache Airflow](https://airflow.apache.org/)